{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DG8CTTFZADAY"
   },
   "source": [
    "##Instalacion de dependecias e importar librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "mjNVHrKhrbpK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )\n",
      "No matching distribution found for tensorflow-gpu\n",
      "You are using pip version 19.0.2, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-de1677d324d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mReshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import  Conv2D,Conv2DTranspose,MaxPooling2D, Flatten, Input, Dense,Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8HzhsFM_cw1"
   },
   "source": [
    "##Definicion de Funciones y clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zw_d7H54XeOc"
   },
   "outputs": [],
   "source": [
    "##Funciones para guardar imagenes a TensorBoard\n",
    "##---------------------------------------------\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def make_image(tensor):\n",
    "\n",
    "    tensor = (tensor*255).astype(np.uint8)\n",
    "    print(tensor.shape)\n",
    "    height, width, channel = tensor.shape\n",
    "    image = Image.fromarray(tensor)\n",
    "    output = io.BytesIO()\n",
    "    image.save(output, format='PNG')\n",
    "    image_string = output.getvalue()\n",
    "    output.close()\n",
    "\n",
    "    return tf.Summary.Image(height=height,\n",
    "                            width=width,\n",
    "                            colorspace=channel,\n",
    "                            encoded_image_string=image_string)\n",
    "  \n",
    "class TensorBoardImage(keras.callbacks.Callback): ##Callback para guardar imagen de prueba\n",
    "\n",
    "    def __init__(self, tag, log_dir):\n",
    "        super().__init__() \n",
    "        self.tag = tag\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        img = self.model.predict(val_gen.__getitem__(0)[0])\n",
    "        image = make_image(img[0])\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=self.tag, image=image)])\n",
    "        dirc = \"./logs/imagen/\" + self.tag\n",
    "        writer = tf.summary.FileWriter(dirc)\n",
    "        writer.add_summary(summary, epoch)\n",
    "        writer.close()\n",
    "        return\n",
    "\n",
    "##Generador Modificado entrenamiento\n",
    "##----------------------------------\n",
    "class Generador(Sequence):\n",
    "  \n",
    "  def __init__(self, genoriginal):\n",
    "    self.gene = genoriginal\n",
    "    \n",
    "  def __len__(self):\n",
    "    return int(self.gene.n/self.gene.batch_size)\n",
    "  \n",
    "  def __getitem__(self, x):\n",
    "    b = self.gene.batch_size\n",
    "    cat= self.gene.__getitem__(x)[1]\n",
    "    items = self.gene.__getitem__(x)[0]\n",
    "    x = []\n",
    "    for item in items:\n",
    "      x.append(item)\n",
    "    return (np.array(x), {\"cla4\": cat, \"dec3\": items})\n",
    "    \n",
    "  def on_epoch_end(self):\n",
    "    print(\"Final de epoca\")\n",
    "\n",
    "##Inicio del servidor TensorBoard y tunnel Ngrok\n",
    "##----------------------------------------------\n",
    "\n",
    "LOG_DIR = './logs/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 --reload_interval 5 &'.format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjD0gFwh_kiW"
   },
   "source": [
    "##Montar unidad de drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ikkqi1Lrr5Ox"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dbq5_UL7_oXu"
   },
   "source": [
    "##Definicion de imagenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EAxsEjlC1d0h"
   },
   "outputs": [],
   "source": [
    "train_path = \"/content/drive/My Drive/DATASETS/entrenamiento/\"\n",
    "val_path = \"/content/drive/My Drive/DATASETS/validacion/\"\n",
    "train_gen = ImageDataGenerator(data_format=\"channels_last\",rescale=1/255).flow_from_directory(train_path, target_size=(256,256),batch_size=10, class_mode=\"binary\")\n",
    "val_gen = ImageDataGenerator(data_format=\"channels_last\",rescale=1/255).flow_from_directory(val_path, target_size=(256,256),batch_size=2, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6MvrGIX_vOR"
   },
   "source": [
    "##Definicion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "o4ekft2HD4ui"
   },
   "outputs": [],
   "source": [
    "#----Entrada----------------------\n",
    "entrada = Input(shape=(256,256,3), name=\"entrada\")\n",
    "#---------------------------------\n",
    "\n",
    "layers_to_freeze = [\"enc1\",\"enc2\",\"enc3\",\"dec1\",\"dec2\",\"dec3\", \"cla1\", \"cla2\", \"cla3\", \"cla4\"] # Lista de capas que se congelaran \n",
    "\n",
    "#Definir capas----------------------\n",
    "#-----------------------------------\n",
    "enc1 = Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", name=\"enc1\")\n",
    "enc2 = Conv2D(filters=32, kernel_size=(4,4), activation=\"relu\", name=\"enc2\")\n",
    "enc3 = Conv2D(filters=64, kernel_size=(4,4), activation=\"relu\", name=\"enc3\")\n",
    "\n",
    "dec1 = Conv2DTranspose(filters=64, kernel_size=(4,4), activation=\"relu\", name=\"dec1\")\n",
    "dec2 = Conv2DTranspose(filters=32, kernel_size=(4,4), activation=\"relu\", name=\"dec2\")\n",
    "dec3 = Conv2DTranspose(filters=3, kernel_size=(5,5), activation=\"sigmoid\", name=\"dec3\")\n",
    "\n",
    "cla1 = Dense(units=256, activation=\"relu\", name=\"cla1\")\n",
    "cla2 = Dense(units=256, activation=\"relu\", name=\"cla2\")\n",
    "cla3 = Dense(units=256, activation=\"relu\", name=\"cla3\")\n",
    "cla4 = Dense(units=1, activation=\"sigmoid\", name=\"cla4\")\n",
    "\n",
    "##Modelo1------------------------------------\n",
    "##-------------------------------------------\n",
    "\n",
    "m11 = enc1(entrada)\n",
    "m12 = enc2(m11)\n",
    "m13 = enc3(m12)\n",
    "m14 = Flatten()(m13)\n",
    "m15 = Reshape((246,246,64))(m14)\n",
    "m16 = dec1(m15)\n",
    "m17 = dec2(m16)\n",
    "m18 = dec3(m17)\n",
    "f2 = Flatten()(m18)\n",
    "m19 = cla1(f2)\n",
    "m20 = cla2(m19)\n",
    "m21 = cla3(m20)\n",
    "m22 = cla4(m21)\n",
    "\n",
    "modelo1 = Model(inputs=entrada, outputs=[m18])\n",
    "modelo1.compile(loss=[\"logcosh\"],optimizer=adam(lr=0.00001, decay=0.00001),metrics=[\"accuracy\"])\n",
    "\n",
    "##Modelo2------------------------------------\n",
    "##-------------------------------------------\n",
    "\n",
    "n11 = enc1(entrada)\n",
    "n12 = enc2(n11)\n",
    "n13 = enc3(n12)\n",
    "n14 = Flatten()(n13)\n",
    "fake1 = Dense(units=256, activation=\"relu\")(n14)\n",
    "fake2 = Dense(units=256, activation=\"relu\")(fake1)\n",
    "fake2 = Dense(units=256, activation=\"relu\")(fake1)\n",
    "fake2 = Dense(units=256, activation=\"relu\")(fake1)\n",
    "fake3 = Dense(units=3873024, activation=\"sigmoid\")(fake2)\n",
    "n15 = Reshape((246,246,64))(fake3)\n",
    "n16 = dec1(n15)\n",
    "n17 = dec2(n16)\n",
    "n18 = dec3(n17)\n",
    "\n",
    "modelo2 = Model(inputs=entrada, outputs=[n18])\n",
    "modelo2.compile(loss=[\"logcosh\"],optimizer=adam(lr=0.0001, decay=0.0001),metrics=[\"accuracy\"])\n",
    "\n",
    "##----Clasificador---------------------------\n",
    "##-------------------------------------------\n",
    "\n",
    "entradaC = Input(shape=(256,256,3), name=\"entradaC\")\n",
    "f3 = Flatten()(entradaC)\n",
    "n19 = cla1(f3)\n",
    "n20 = cla2(n19)\n",
    "n21 = cla3(n20)\n",
    "n22 = cla4(n21)\n",
    "\n",
    "clasificador = Model(inputs=entradaC, outputs=[n22])\n",
    "clasificador.compile(loss=[\"binary_crossentropy\"], optimizer=adam(lr=0.0001, decay=0.0001),metrics=[\"accuracy\"])\n",
    "\n",
    "#------------------------------------------------\n",
    "#------------------------------------------------\n",
    "##--Funciones para congelar y descongelar pesos\n",
    "\n",
    "def congelar_pesos(modelo):\n",
    "  for layer in modelo.layers:\n",
    "    if layer.name in layers_to_freeze:\n",
    "      layer.trainable = False\n",
    "\n",
    "def descongelar_pesos(modelo):\n",
    "  for layer in modelo.layers:\n",
    "    if layer.name in layers_to_freeze:\n",
    "      layer.trainable = True\n",
    "\n",
    "##------------------------------------------------\n",
    "##------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F5hdpRkySwea"
   },
   "outputs": [],
   "source": [
    "clasificador.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8rjAg-xBqw3"
   },
   "source": [
    "##Entrenamiento modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4iB9rkNmeTO-"
   },
   "outputs": [],
   "source": [
    "logDir = \"./logs/escalar/\"+ str(datetime.datetime.now().time()) #Directorio de logs\n",
    "nameImagen = str(datetime.datetime.now().time()) #Nombre de la imagen predicha por el modelo\n",
    "\n",
    "tbimg= TensorBoardImage(tag=nameImagen, log_dir= logDir)  ##Callback que escribe imagen de prediccion del modelo\n",
    "tb = TensorBoard(log_dir=logDir, histogram_freq=0,write_graph=True,write_grads=True,write_images=True) ##Callback de Loss y accuracy\n",
    "\n",
    "gen = Generador(train_gen) #Iniciacion del Generador modificado\n",
    "\n",
    "#modelo1.fit(x=gen.__getitem__(0)[0],y=gen.__getitem__(0)[1],epochs=10)\n",
    "modelo1.fit_generator(generator = gen, steps_per_epoch=1,epochs=100,shuffle=True, callbacks=[tb,tbimg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5-Npyh1_9K_"
   },
   "source": [
    "##Generar video de muestra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jkZv7xFwpTNz"
   },
   "outputs": [],
   "source": [
    "im = val_gen.__getitem__(0)[0]\n",
    "\n",
    "m = modelo1.predict(im)\n",
    "print(m[0].shape)\n",
    "#plt.imshow((img[0]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HMSPWL4mUllc"
   },
   "outputs": [],
   "source": [
    "# def entrenar(epocas,nrandom):\n",
    "#   i= 0\n",
    "#   for b in train_batch:\n",
    "#     i+=1\n",
    "#     if i >= epocas:\n",
    "\n",
    "#       #print(\"MOD\")\n",
    "#       modelo.metrics_names, modelo.train_on_batch(x=b[0],y=b[0])\n",
    "#       im =modelo.predict(val_batch[nrandom][0])\n",
    "#       #plt.imshow(im[0])\n",
    "#       #plt.show()\n",
    "#       return im[0]\n",
    "#       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "A2fOgjZYORZC"
   },
   "outputs": [],
   "source": [
    "# fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# video = cv2.VideoWriter('/content/drive/My Drive/DATASETS/entrenamiento/video{}.avi'.format(nrandom), fourcc, 30, (256, 256), True)\n",
    "# for j in img:\n",
    "#   #print(np.uint8(j*255))\n",
    "#   video.write(np.uint8(j*100))\n",
    "# video.release()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "GAN1.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
